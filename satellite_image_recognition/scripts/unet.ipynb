{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import numpy as np \n",
    "import os\n",
    "import glob\n",
    "#import cv2\n",
    "#from libtiff import TIFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = '14'\n",
    "tile_base_path = '../media/combined_37_UDB/%s' % z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_dirs = os.listdir(tile_base_path)\n",
    "train_dirs = photo_dirs[:int(len(photo_dirs) * 0.2)]\n",
    "test_dirs = photo_dirs[int(len(photo_dirs) * 0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class myAugmentation(object):\n",
    "\n",
    "    \"\"\"\n",
    "    A class used to augmentate image\n",
    "    Firstly, read train image and label seperately, and then merge them together for the next process\n",
    "    Secondly, use keras preprocessing to augmentate image\n",
    "    Finally, seperate augmentated image apart into train image and label\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, train_path=\"train\", label_path=\"label\", merge_path=\"merge\", aug_merge_path=\"aug_merge\", aug_train_path=\"aug_train\", aug_label_path=\"aug_label\", img_type=\"tif\"):\n",
    "\n",
    "        \"\"\"\n",
    "        Using glob to get all .img_type form path\n",
    "        \"\"\"\n",
    "\n",
    "        self.train_imgs = glob.glob(train_path+\"/*.\"+img_type)\n",
    "        self.label_imgs = glob.glob(label_path+\"/*.\"+img_type)\n",
    "        self.train_path = train_path\n",
    "        self.label_path = label_path\n",
    "        self.merge_path = merge_path\n",
    "        self.img_type = img_type\n",
    "        self.aug_merge_path = aug_merge_path\n",
    "        self.aug_train_path = aug_train_path\n",
    "        self.aug_label_path = aug_label_path\n",
    "        self.slices = len(self.train_imgs)\n",
    "        self.datagen = ImageDataGenerator(\n",
    "                                    rotation_range=0.2,\n",
    "                                    width_shift_range=0.05,\n",
    "                                    height_shift_range=0.05,\n",
    "                                    shear_range=0.05,\n",
    "                                    zoom_range=0.05,\n",
    "                                    horizontal_flip=True,\n",
    "                                    fill_mode='nearest')\n",
    "\n",
    "    def Augmentation(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Start augmentation.....\n",
    "        \"\"\"\n",
    "        trains = self.train_imgs\n",
    "        labels = self.label_imgs\n",
    "        path_train = self.train_path\n",
    "        path_label = self.label_path\n",
    "        path_merge = self.merge_path\n",
    "        imgtype = self.img_type\n",
    "        path_aug_merge = self.aug_merge_path\n",
    "        if len(trains) != len(labels) or len(trains) == 0 or len(trains) == 0:\n",
    "            print(\"trains can't match labels\")\n",
    "            return 0\n",
    "        for i in range(len(trains)):\n",
    "            img_t = load_img(path_train+\"/\"+str(i)+\".\"+imgtype)\n",
    "            img_l = load_img(path_label+\"/\"+str(i)+\".\"+imgtype)\n",
    "            x_t = img_to_array(img_t)\n",
    "            x_l = img_to_array(img_l)\n",
    "            x_t[:,:,2] = x_l[:,:,0]\n",
    "            img_tmp = array_to_img(x_t)\n",
    "            img_tmp.save(path_merge+\"/\"+str(i)+\".\"+imgtype)\n",
    "            img = x_t\n",
    "            img = img.reshape((1,) + img.shape)\n",
    "            savedir = path_aug_merge + \"/\" + str(i)\n",
    "            if not os.path.lexists(savedir):\n",
    "                os.mkdir(savedir)\n",
    "            self.doAugmentate(img, savedir, str(i))\n",
    "\n",
    "\n",
    "    def doAugmentate(self, img, save_to_dir, save_prefix, batch_size=1, save_format='tif', imgnum=30):\n",
    "\n",
    "        \"\"\"\n",
    "        augmentate one image\n",
    "        \"\"\"\n",
    "        datagen = self.datagen\n",
    "        i = 0\n",
    "        for batch in datagen.flow(img,\n",
    "                          batch_size=batch_size,\n",
    "                          save_to_dir=save_to_dir,\n",
    "                          save_prefix=save_prefix,\n",
    "                          save_format=save_format):\n",
    "            i += 1\n",
    "            if i > imgnum:\n",
    "                break\n",
    "\n",
    "    def splitMerge(self):\n",
    "\n",
    "        \"\"\"\n",
    "        split merged image apart\n",
    "        \"\"\"\n",
    "        path_merge = self.aug_merge_path\n",
    "        path_train = self.aug_train_path\n",
    "        path_label = self.aug_label_path\n",
    "        for i in range(self.slices):\n",
    "            path = path_merge + \"/\" + str(i)\n",
    "            train_imgs = glob.glob(path+\"/*.\"+self.img_type)\n",
    "            savedir = path_train + \"/\" + str(i)\n",
    "            if not os.path.lexists(savedir):\n",
    "                os.mkdir(savedir)\n",
    "            savedir = path_label + \"/\" + str(i)\n",
    "            if not os.path.lexists(savedir):\n",
    "                os.mkdir(savedir)\n",
    "            for imgname in train_imgs:\n",
    "                midname = imgname[imgname.rindex(\"/\")+1:imgname.rindex(\".\"+self.img_type)]\n",
    "                img = cv2.imread(imgname)\n",
    "                img_train = img[:,:,2]#cv2 read image rgb->bgr\n",
    "                img_label = img[:,:,0]\n",
    "                cv2.imwrite(path_train+\"/\"+str(i)+\"/\"+midname+\"_train\"+\".\"+self.img_type,img_train)\n",
    "                cv2.imwrite(path_label+\"/\"+str(i)+\"/\"+midname+\"_label\"+\".\"+self.img_type,img_label)\n",
    "\n",
    "    def splitTransform(self):\n",
    "\n",
    "        \"\"\"\n",
    "        split perspective transform images\n",
    "        \"\"\"\n",
    "        #path_merge = \"transform\"\n",
    "        #path_train = \"transform/data/\"\n",
    "        #path_label = \"transform/label/\"\n",
    "        path_merge = \"deform/deform_norm2\"\n",
    "        path_train = \"deform/train/\"\n",
    "        path_label = \"deform/label/\"\n",
    "        train_imgs = glob.glob(path_merge+\"/*.\"+self.img_type)\n",
    "        for imgname in train_imgs:\n",
    "            midname = imgname[imgname.rindex(\"/\")+1:imgname.rindex(\".\"+self.img_type)]\n",
    "            img = cv2.imread(imgname)\n",
    "            img_train = img[:,:,2]#cv2 read image rgb->bgr\n",
    "            img_label = img[:,:,0]\n",
    "            cv2.imwrite(path_train+midname+\".\"+self.img_type,img_train)\n",
    "            cv2.imwrite(path_label+midname+\".\"+self.img_type,img_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class dataProcess(object):\n",
    "\n",
    "    def __init__(self, out_rows, out_cols, data_path = \"../media/combined_37_UDB/14/\", label_path = \"../media/combined_37_UDB/14/\", \n",
    "                 train_dirs = train_dirs, test_dirs = test_dirs, test_path =  \"../media/combined_37_UDB/14/\", npy_path = \"../media/combined_37_UDB/14/\", img_type = \"png\"):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        self.out_rows = out_rows\n",
    "        self.out_cols = out_cols\n",
    "        self.data_path = data_path\n",
    "        self.label_path = label_path\n",
    "        self.img_type = img_type\n",
    "        self.test_path = test_path\n",
    "        self.npy_path = npy_path\n",
    "\n",
    "    def create_train_data(self):\n",
    "        print('-'*30)\n",
    "        print('Creating training images...')\n",
    "        print('-'*30)\n",
    "        imgs = []\n",
    "        for train_dir in train_dirs:\n",
    "            imgs.extend([x for x in glob.glob(\"../media/combined_37_UDB/14/%s\" % train_dir +\"/*.\"+\"png\") if 'mask' not in x])\n",
    "        print(len(imgs))\n",
    "        imgdatas = np.ndarray((len(imgs), 256, 256, 1), dtype=np.uint8)\n",
    "        imglabels = np.ndarray((len(imgs), 256, 256,1), dtype=np.uint8) # buildings\n",
    "        \n",
    "        i = 0\n",
    "        for imgname in imgs:\n",
    "            midname = imgname[imgname.rindex(\"/\")+1:]\n",
    "            img = load_img(imgname,grayscale = True)\n",
    "            try:\n",
    "                label = load_img(imgname.split('\\\\')[0]  + '/' + imgname.split('\\\\')[1].split('.')[0] + '_mask.png',grayscale = True)\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "            img = img_to_array(img)\n",
    "            label = img_to_array(label)\n",
    "            \n",
    "            imgdatas[i] = img\n",
    "            imglabels[i] = label\n",
    "            \n",
    "            i += 1\n",
    "            \n",
    "        print('loading done')\n",
    "        np.save(self.npy_path + '/imgs_train.npy', imgdatas)\n",
    "        np.save(self.npy_path + '/imgs_mask_train.npy', imglabels)\n",
    "        print('Saving to .npy files done.')\n",
    "\n",
    "    def create_test_data(self):\n",
    "        i = 0\n",
    "        print('-'*30)\n",
    "        print('Creating test images...')\n",
    "        print('-'*30)\n",
    "        imgs = []\n",
    "        for test_dir in test_dirs:\n",
    "            imgs.extend([x for x in glob.glob(\"../media/combined_37_UDB/14/%s\" % test_dir +\"/*.\"+\"png\") if 'mask' not in x])\n",
    "        print(len(imgs))\n",
    "        imgdatas = np.ndarray((len(imgs),256,256,1), dtype=np.uint8)\n",
    "        \n",
    "        i = 0\n",
    "        for imgname in imgs:\n",
    "            midname = imgname[imgname.rindex(\"/\")+1:]\n",
    "            img = load_img(imgname,grayscale = True)\n",
    "            img = img_to_array(img)\n",
    "            \n",
    "            imgdatas[i] = img\n",
    "            \n",
    "            i += 1\n",
    "\n",
    "        print('loading done')\n",
    "        np.save(self.npy_path + '/imgs_test.npy', imgdatas)\n",
    "        print('Saving to imgs_test.npy files done.')\n",
    "\n",
    "    def load_train_data(self, tp = 'roads'):\n",
    "        print('-'*30)\n",
    "        print('load train images...')\n",
    "        print('-'*30)\n",
    "        imgs_train = np.load(self.npy_path+\"/imgs_train.npy\")\n",
    "        if tp == 'roads':\n",
    "            imgs_mask_train = np.load(self.npy_path+\"/imgs_mask_train.npy\")\n",
    "        imgs_train = imgs_train.astype('float32')\n",
    "        imgs_mask_train = imgs_mask_train.astype('float32')\n",
    "        imgs_train /= 255\n",
    "        imgs_mask_train /= 255\n",
    "        imgs_mask_train[imgs_mask_train > 0.5] = 1\n",
    "        imgs_mask_train[imgs_mask_train <= 0.5] = 0\n",
    "        return imgs_train,imgs_mask_train\n",
    "\n",
    "    def load_test_data(self):\n",
    "        print('-'*30)\n",
    "        print('load test images...')\n",
    "        print('-'*30)\n",
    "        imgs_test = np.load(self.npy_path+\"/imgs_test.npy\")\n",
    "        imgs_test = imgs_test.astype('float32')\n",
    "        imgs_test /= 255\n",
    "        return imgs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Creating training images...\n",
      "------------------------------\n",
      "500\n",
      "loading done\n",
      "Saving to .npy files done.\n",
      "------------------------------\n",
      "Creating test images...\n",
      "------------------------------\n",
      "650\n",
      "loading done\n",
      "Saving to imgs_test.npy files done.\n"
     ]
    }
   ],
   "source": [
    "#aug = myAugmentation()\n",
    "#aug.Augmentation()\n",
    "#aug.splitMerge()\n",
    "#aug.splitTransform()\n",
    "mydata = dataProcess(256,256)\n",
    "mydata.create_train_data()\n",
    "mydata.create_test_data()\n",
    "#imgs_train,imgs_mask_train = mydata.load_train_data()\n",
    "#print imgs_train.shape,imgs_mask_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import *\n",
    "from keras.layers import Input, merge, Conv2D, MaxPooling2D, UpSampling2D, Dropout, Cropping2D, Convolution2D, core, BatchNormalization\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.layers.core import Lambda\n",
    "import keras\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.backend import binary_crossentropy\n",
    "\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allocator_type ='BFC'\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:File `\"'data.ipynb'.py\"` not found.\n"
     ]
    }
   ],
   "source": [
    "# %run 'data.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def slice_batch(x, n_gpus, part):\n",
    "    \"\"\"\n",
    "    Divide the input batch into [n_gpus] slices, and obtain slice no.\n",
    "    [part].\n",
    "\n",
    "    i.e. if len(x)=10, then slice_batch(x, 2, 1) will return x[5:].\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    sh = K.shape(x)\n",
    "\n",
    "    L = sh[0] / n_gpus\n",
    "    L = tf.cast(L, tf.int32)\n",
    "\n",
    "    if part == n_gpus - 1:\n",
    "\n",
    "        return x[part*L:]\n",
    "\n",
    "    return x[part*L:int(part+1)*L]\n",
    "\n",
    "def to_multi_gpu(model, n_gpus=4):\n",
    "\n",
    "    \"\"\"Given a keras [model], return an equivalent model which parallelizes\n",
    "\n",
    "    the computation over [n_gpus] GPUs.\n",
    "\n",
    "\n",
    "\n",
    "    Each GPU gets a slice of the input batch, applies the model on that\n",
    "    slice\n",
    "\n",
    "    and later the outputs of the models are concatenated to a single\n",
    "    tensor,\n",
    "\n",
    "    hence the user sees a model that behaves the same as the original.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    with tf.device('/cpu:0'):\n",
    "\n",
    "        x = Input(model.input_shape[1:], name=model.input_names[0])\n",
    "\n",
    "\n",
    "    towers = []\n",
    "\n",
    "    for g in range(n_gpus):\n",
    "\n",
    "        with tf.device('/gpu:' + str(g)):\n",
    "\n",
    "            slice_g = Lambda(slice_batch, lambda shape: shape, arguments={'n_gpus':n_gpus, 'part':g})(x)\n",
    "\n",
    "            towers.append(model(slice_g))\n",
    "\n",
    "\n",
    "    with tf.device('/cpu:0'):\n",
    "\n",
    "        merged = merge(towers, mode='concat', concat_axis=0)\n",
    "\n",
    "    new_model = Model(input=[x], output=merged)\n",
    "    \n",
    "    funcType = type(model.save)\n",
    "    # monkeypatch the save to save just the underlying model\n",
    "    def new_save(self_,filepath, overwrite=True):\n",
    "        model.save(filepath, overwrite)\n",
    "    new_model.save=funcType(new_save, new_model)\n",
    "   \n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smooth = 1e-12\n",
    "\n",
    "def jaccard_coef(y_true, y_pred):\n",
    "    intersection = K.sum(y_true * y_pred, axis=[0, -1, -2])\n",
    "    sum_ = K.sum(y_true + y_pred, axis=[0, -1, -2])\n",
    "\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "\n",
    "    return K.mean(jac)\n",
    "\n",
    "\n",
    "def jaccard_coef_int(y_true, y_pred):\n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "\n",
    "    intersection = K.sum(y_true * y_pred_pos, axis=[0, -1, -2])\n",
    "    sum_ = K.sum(y_true + y_pred_pos, axis=[0, -1, -2])\n",
    "\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "\n",
    "    return K.mean(jac)\n",
    "\n",
    "\n",
    "def jaccard_coef_loss(y_true, y_pred):\n",
    "    return -K.log(jaccard_coef(y_true, y_pred)) + binary_crossentropy(y_pred, y_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class myUnet(object):\n",
    "\n",
    "    def __init__(self, tp = 'roads', img_rows = 256, img_cols = 256):\n",
    "\n",
    "        self.type = tp\n",
    "        self.img_rows = img_rows\n",
    "        self.img_cols = img_cols\n",
    "\n",
    "    def load_data(self):\n",
    "\n",
    "        mydata = dataProcess(self.img_rows, self.img_cols)\n",
    "        imgs_train, imgs_mask_train = mydata.load_train_data(self.type)\n",
    "        imgs_test = mydata.load_test_data()\n",
    "        return imgs_train, imgs_mask_train, imgs_test\n",
    "\n",
    "    #Define the neural network\n",
    "    def get_unet(self):\n",
    "        inputs = Input((256, 256, 1))\n",
    "        #\n",
    "        conv1 = Convolution2D(32, 3, 3, border_mode='same', kernel_initializer = 'he_normal')(inputs)\n",
    "        conv1 = BatchNormalization(mode=0, axis=1)(conv1)\n",
    "        conv1 = keras.layers.advanced_activations.ELU()(conv1)\n",
    "        conv1 = Convolution2D(32, 3, 3, border_mode='same', kernel_initializer = 'he_normal')(conv1)\n",
    "        conv1 = BatchNormalization(mode=0, axis=1)(conv1)\n",
    "        conv1 = keras.layers.advanced_activations.ELU()(conv1)\n",
    "        pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "        #\n",
    "        conv2 = Convolution2D(64, 3, 3, border_mode='same', kernel_initializer = 'he_normal')(pool1)\n",
    "        conv2 = BatchNormalization(mode=0, axis=1)(conv2)\n",
    "        conv2 = keras.layers.advanced_activations.ELU()(conv2)\n",
    "        conv2 = Convolution2D(64, 3, 3, activation='relu', border_mode='same', kernel_initializer = 'he_normal')(conv2)\n",
    "        conv2 = BatchNormalization(mode=0, axis=1)(conv2)\n",
    "        conv2 = keras.layers.advanced_activations.ELU()(conv2)\n",
    "        pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "        #\n",
    "        conv3 = Convolution2D(128, 3, 3, border_mode='same', kernel_initializer = 'he_normal')(pool2)\n",
    "        conv3 = BatchNormalization(mode=0, axis=1)(conv3)\n",
    "        conv3 = keras.layers.advanced_activations.ELU()(conv3)\n",
    "        conv3 = Convolution2D(128, 3, 3, border_mode='same', kernel_initializer = 'he_normal')(conv3)\n",
    "        conv3 = BatchNormalization(mode=0, axis=1)(conv3)\n",
    "        conv3 = keras.layers.advanced_activations.ELU()(conv3)\n",
    "        pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "        #\n",
    "        conv4 = Convolution2D(256, 3, 3, border_mode='same', kernel_initializer = 'he_normal')(pool3)\n",
    "        conv4 = BatchNormalization(mode=0, axis=1)(conv4)\n",
    "        conv4 = keras.layers.advanced_activations.ELU()(conv4)\n",
    "        conv4 = Convolution2D(256, 3, 3, border_mode='same', kernel_initializer = 'he_normal')(conv4)\n",
    "        conv4 = BatchNormalization(mode=0, axis=1)(conv4)\n",
    "        conv4 = keras.layers.advanced_activations.ELU()(conv4)\n",
    "        drop4 = Dropout(0.5)(conv4)\n",
    "#         pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "        #\n",
    "#         conv5 = Convolution2D(512, 3, 3, border_mode='same', kernel_initializer='he_normal')(pool4)\n",
    "#         conv5 = BatchNormalization(mode=0, axis=1)(conv5)\n",
    "#         conv5 = keras.layers.advanced_activations.ELU()(conv5)\n",
    "#         conv5 = Convolution2D(512, 3, 3, border_mode='same', kernel_initializer='he_normal')(conv5)\n",
    "#         conv5 = BatchNormalization(mode=0, axis=1)(conv5)\n",
    "#         conv5 = keras.layers.advanced_activations.ELU()(conv5)\n",
    "#         drop5 = Dropout(0.5)(conv5)\n",
    "        #\n",
    "#         up1 = merge([UpSampling2D(size=(2, 2))(conv5), conv4], mode='concat', concat_axis=-1)\n",
    "#         conv6 = Convolution2D(256, 3, 3, border_mode='same', kernel_initializer = 'he_normal')(up1)\n",
    "#         conv6 = BatchNormalization(mode=0, axis=1)(conv6)\n",
    "#         conv6 = keras.layers.advanced_activations.ELU()(conv6)\n",
    "#         conv6 = Convolution2D(256, 3, 3, border_mode='same', kernel_initializer = 'he_normal')(conv6)\n",
    "#         conv6 = BatchNormalization(mode=0, axis=1)(conv6)\n",
    "#         conv6 = keras.layers.advanced_activations.ELU()(conv6)\n",
    "        #\n",
    "        up1 = merge([UpSampling2D(size=(2, 2))(conv4), conv3], mode='concat', concat_axis=-1)\n",
    "        conv7 = Convolution2D(128, 3, 3, border_mode='same', kernel_initializer = 'he_normal')(up1)\n",
    "        conv7 = BatchNormalization(mode=0, axis=1)(conv7)\n",
    "        conv7 = keras.layers.advanced_activations.ELU()(conv7)\n",
    "        conv7 = Convolution2D(128, 3, 3, border_mode='same', kernel_initializer = 'he_normal')(conv7)\n",
    "        conv7 = BatchNormalization(mode=0, axis=1)(conv7)\n",
    "        conv7 = keras.layers.advanced_activations.ELU()(conv7)\n",
    "        #\n",
    "        up3 = merge([UpSampling2D(size=(2, 2))(conv7), conv2], mode='concat', concat_axis=-1)\n",
    "        conv8 = Convolution2D(64, 3, 3, border_mode='same', kernel_initializer='he_normal')(up3)\n",
    "        conv8 = BatchNormalization(mode=0, axis=1)(conv8)\n",
    "        conv8 = keras.layers.advanced_activations.ELU()(conv8)\n",
    "        conv8 = Convolution2D(64, 3, 3, border_mode='same', kernel_initializer='he_normal')(conv8)\n",
    "        conv8 = BatchNormalization(mode=0, axis=1)(conv8)\n",
    "        conv8 = keras.layers.advanced_activations.ELU()(conv8)\n",
    "        #\n",
    "        up4 = merge([UpSampling2D(size=(2, 2))(conv8), conv1], mode='concat', concat_axis=-1)\n",
    "        conv9 = Convolution2D(32, 3, 3, border_mode='same', kernel_initializer = 'he_normal')(up4)\n",
    "        conv9 = BatchNormalization(mode=0, axis=1)(conv9)\n",
    "        conv9 = keras.layers.advanced_activations.ELU()(conv9)\n",
    "        conv9 = Convolution2D(32, 3, 3, border_mode='same', kernel_initializer = 'he_normal')(conv9)\n",
    "        conv9 = BatchNormalization(mode=0, axis=1)(conv9)\n",
    "        conv9 = keras.layers.advanced_activations.ELU()(conv9)\n",
    "        conv9 = Convolution2D(2, 3, 3, border_mode='same', kernel_initializer = 'he_normal')(conv9)\n",
    "        #\n",
    "        conv10 = Convolution2D(1, 1, 1, activation='sigmoid')(conv9)\n",
    "\n",
    "        model = Model(input=inputs, output=conv10)\n",
    "\n",
    "        model.compile(optimizer= Nadam(lr = 1e-3), loss=jaccard_coef_loss, metrics=['binary_crossentropy', jaccard_coef_int])\n",
    "        model = to_multi_gpu(model)\n",
    "        model.compile(optimizer= Nadam(lr = 1e-3), loss=jaccard_coef_loss, metrics=['binary_crossentropy', jaccard_coef_int])\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        print(\"loading data\")\n",
    "        imgs_train, imgs_mask_train, imgs_test = self.load_data()\n",
    "        print(\"loading data done\")\n",
    "        model = self.get_unet()\n",
    "        print(\"got unet\")\n",
    "\n",
    "        model_checkpoint = ModelCheckpoint('sentinesl_unet_roads.hdf5', monitor='loss',verbose=1, save_best_only=True, mode='min')\n",
    "        print('Fitting model...')\n",
    "        model.fit(imgs_train, imgs_mask_train, batch_size=8, nb_epoch=50, verbose=1, validation_split=0.3, shuffle=True, callbacks=[model_checkpoint])\n",
    "\n",
    "        \n",
    "        print('predict test data')\n",
    "        imgs_mask_test = model.predict(imgs_test, batch_size=8, verbose=1)\n",
    "        if self.type == 'roads':\n",
    "            np.save('../results/imgs_mask_test.npy', imgs_mask_test)\n",
    "        elif self.type == 'cars':\n",
    "            np.save('../results/imgs_mask_test_cars.npy', imgs_mask_test)\n",
    "\n",
    "    def save_img(self):\n",
    "\n",
    "        print(\"array to image\")\n",
    "        if self.tp == 'roads':\n",
    "            imgs = np.load('../results/imgs_mask_test.npy')\n",
    "        elif self.tp == 'cars':\n",
    "            imgs = np.load('../results/imgs_mask_test_cars.npy')\n",
    "        for i in range(imgs.shape[0]):\n",
    "            img = imgs[i]\n",
    "            img = array_to_img(img)\n",
    "            img.save(\"../results/%d.jpg\"%(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "------------------------------\n",
      "load train images...\n",
      "------------------------------\n",
      "------------------------------\n",
      "load test images...\n",
      "------------------------------\n",
      "loading data done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), kernel_initializer=\"he_normal\", padding=\"same\")`\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(axis=1)`\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:23: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), kernel_initializer=\"he_normal\", padding=\"same\")`\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(axis=1)`\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), kernel_initializer=\"he_normal\", padding=\"same\")`\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:29: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(axis=1)`\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:31: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")`\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:32: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(axis=1)`\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:36: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), kernel_initializer=\"he_normal\", padding=\"same\")`\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:37: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(axis=1)`\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:39: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), kernel_initializer=\"he_normal\", padding=\"same\")`\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:40: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(axis=1)`\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:44: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), kernel_initializer=\"he_normal\", padding=\"same\")`\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:45: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(axis=1)`\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:47: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), kernel_initializer=\"he_normal\", padding=\"same\")`\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:48: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(axis=1)`\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:69: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\legacy\\layers.py:465: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:70: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), kernel_initializer=\"he_normal\", padding=\"same\")`\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:71: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(axis=1)`\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:73: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), kernel_initializer=\"he_normal\", padding=\"same\")`\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:74: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(axis=1)`\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:77: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:78: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), kernel_initializer=\"he_normal\", padding=\"same\")`\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:79: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(axis=1)`\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:81: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), kernel_initializer=\"he_normal\", padding=\"same\")`\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:82: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(axis=1)`\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:85: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:86: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), kernel_initializer=\"he_normal\", padding=\"same\")`\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:87: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(axis=1)`\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:89: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), kernel_initializer=\"he_normal\", padding=\"same\")`\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:90: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(axis=1)`\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:92: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(2, (3, 3), kernel_initializer=\"he_normal\", padding=\"same\")`\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:94: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1, (1, 1), activation=\"sigmoid\")`\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:96: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"co..., inputs=Tensor(\"in...)`\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:57: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:59: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"me..., inputs=[<tf.Tenso...)`\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:115: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got unet\n",
      "Fitting model...\n",
      "Train on 350 samples, validate on 150 samples\n",
      "Epoch 1/50\n",
      "350/350 [==============================] - 1213s 3s/step - loss: 7.5754 - binary_crossentropy: 0.0872 - jaccard_coef_int: 0.0999 - val_loss: 7.9113 - val_binary_crossentropy: 0.0125 - val_jaccard_coef_int: 0.1365\n",
      "\n",
      "Epoch 00001: loss improved from inf to 7.57543, saving model to sentinesl_unet_roads.hdf5\n",
      "Epoch 2/50\n",
      "350/350 [==============================] - 1227s 4s/step - loss: 6.8496 - binary_crossentropy: 0.0188 - jaccard_coef_int: 0.0833 - val_loss: 8.0230 - val_binary_crossentropy: 0.0117 - val_jaccard_coef_int: 0.1365\n",
      "\n",
      "Epoch 00002: loss improved from 7.57543 to 6.84957, saving model to sentinesl_unet_roads.hdf5\n",
      "Epoch 3/50\n",
      "280/350 [=======================>......] - ETA: 3:17 - loss: 6.7067 - binary_crossentropy: 0.0202 - jaccard_coef_int: 0.0373"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-efcc6b5955b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmyunet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmyUnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'roads'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmyunet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-4050fd704662>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[0mmodel_checkpoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sentinesl_unet_roads.hdf5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'min'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Fitting model...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgs_mask_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2478\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2479\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1140\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1141\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1321\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1312\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[0;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1420\u001b[1;33m             status, run_metadata)\n\u001b[0m\u001b[0;32m   1421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1422\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "myunet = myUnet('roads')\n",
    "myunet.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# myunet = myUnet('cars')\n",
    "# myunet.train()\n",
    "# # myunet.save_img()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**load**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # define the checkpoint\n",
    "# filepath=\"results/weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
    "# checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "# callbacks_list = [checkpoint]\n",
    "\n",
    "# # fit the model\n",
    "# model.fit(X, y, epochs=50, batch_size=64, callbacks=callbacks_list)\n",
    "\n",
    "# # load the network weights\n",
    "# filename = \"results/weights-improvement-49-0.4748-bigger.hdf5\"\n",
    "# model.load_weights(filename)\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
