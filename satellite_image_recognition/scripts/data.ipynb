{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import numpy as np \n",
    "import os\n",
    "import glob\n",
    "#import cv2\n",
    "#from libtiff import TIFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = '14'\n",
    "tile_base_path = '../media/combined_37_UDB/%s' % z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_dirs = os.listdir(tile_base_path)\n",
    "train_dirs = photo_dirs[:int(len(photo_dirs) * 0.2)]\n",
    "test_dirs = photo_dirs[int(len(photo_dirs) * 0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class myAugmentation(object):\n",
    "\n",
    "    \"\"\"\n",
    "    A class used to augmentate image\n",
    "    Firstly, read train image and label seperately, and then merge them together for the next process\n",
    "    Secondly, use keras preprocessing to augmentate image\n",
    "    Finally, seperate augmentated image apart into train image and label\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, train_path=\"train\", label_path=\"label\", merge_path=\"merge\", aug_merge_path=\"aug_merge\", aug_train_path=\"aug_train\", aug_label_path=\"aug_label\", img_type=\"tif\"):\n",
    "\n",
    "        \"\"\"\n",
    "        Using glob to get all .img_type form path\n",
    "        \"\"\"\n",
    "\n",
    "        self.train_imgs = glob.glob(train_path+\"/*.\"+img_type)\n",
    "        self.label_imgs = glob.glob(label_path+\"/*.\"+img_type)\n",
    "        self.train_path = train_path\n",
    "        self.label_path = label_path\n",
    "        self.merge_path = merge_path\n",
    "        self.img_type = img_type\n",
    "        self.aug_merge_path = aug_merge_path\n",
    "        self.aug_train_path = aug_train_path\n",
    "        self.aug_label_path = aug_label_path\n",
    "        self.slices = len(self.train_imgs)\n",
    "        self.datagen = ImageDataGenerator(\n",
    "                                    rotation_range=0.2,\n",
    "                                    width_shift_range=0.05,\n",
    "                                    height_shift_range=0.05,\n",
    "                                    shear_range=0.05,\n",
    "                                    zoom_range=0.05,\n",
    "                                    horizontal_flip=True,\n",
    "                                    fill_mode='nearest')\n",
    "\n",
    "    def Augmentation(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Start augmentation.....\n",
    "        \"\"\"\n",
    "        trains = self.train_imgs\n",
    "        labels = self.label_imgs\n",
    "        path_train = self.train_path\n",
    "        path_label = self.label_path\n",
    "        path_merge = self.merge_path\n",
    "        imgtype = self.img_type\n",
    "        path_aug_merge = self.aug_merge_path\n",
    "        if len(trains) != len(labels) or len(trains) == 0 or len(trains) == 0:\n",
    "            print(\"trains can't match labels\")\n",
    "            return 0\n",
    "        for i in range(len(trains)):\n",
    "            img_t = load_img(path_train+\"/\"+str(i)+\".\"+imgtype)\n",
    "            img_l = load_img(path_label+\"/\"+str(i)+\".\"+imgtype)\n",
    "            x_t = img_to_array(img_t)\n",
    "            x_l = img_to_array(img_l)\n",
    "            x_t[:,:,2] = x_l[:,:,0]\n",
    "            img_tmp = array_to_img(x_t)\n",
    "            img_tmp.save(path_merge+\"/\"+str(i)+\".\"+imgtype)\n",
    "            img = x_t\n",
    "            img = img.reshape((1,) + img.shape)\n",
    "            savedir = path_aug_merge + \"/\" + str(i)\n",
    "            if not os.path.lexists(savedir):\n",
    "                os.mkdir(savedir)\n",
    "            self.doAugmentate(img, savedir, str(i))\n",
    "\n",
    "\n",
    "    def doAugmentate(self, img, save_to_dir, save_prefix, batch_size=1, save_format='tif', imgnum=30):\n",
    "\n",
    "        \"\"\"\n",
    "        augmentate one image\n",
    "        \"\"\"\n",
    "        datagen = self.datagen\n",
    "        i = 0\n",
    "        for batch in datagen.flow(img,\n",
    "                          batch_size=batch_size,\n",
    "                          save_to_dir=save_to_dir,\n",
    "                          save_prefix=save_prefix,\n",
    "                          save_format=save_format):\n",
    "            i += 1\n",
    "            if i > imgnum:\n",
    "                break\n",
    "\n",
    "    def splitMerge(self):\n",
    "\n",
    "        \"\"\"\n",
    "        split merged image apart\n",
    "        \"\"\"\n",
    "        path_merge = self.aug_merge_path\n",
    "        path_train = self.aug_train_path\n",
    "        path_label = self.aug_label_path\n",
    "        for i in range(self.slices):\n",
    "            path = path_merge + \"/\" + str(i)\n",
    "            train_imgs = glob.glob(path+\"/*.\"+self.img_type)\n",
    "            savedir = path_train + \"/\" + str(i)\n",
    "            if not os.path.lexists(savedir):\n",
    "                os.mkdir(savedir)\n",
    "            savedir = path_label + \"/\" + str(i)\n",
    "            if not os.path.lexists(savedir):\n",
    "                os.mkdir(savedir)\n",
    "            for imgname in train_imgs:\n",
    "                midname = imgname[imgname.rindex(\"/\")+1:imgname.rindex(\".\"+self.img_type)]\n",
    "                img = cv2.imread(imgname)\n",
    "                img_train = img[:,:,2]#cv2 read image rgb->bgr\n",
    "                img_label = img[:,:,0]\n",
    "                cv2.imwrite(path_train+\"/\"+str(i)+\"/\"+midname+\"_train\"+\".\"+self.img_type,img_train)\n",
    "                cv2.imwrite(path_label+\"/\"+str(i)+\"/\"+midname+\"_label\"+\".\"+self.img_type,img_label)\n",
    "\n",
    "    def splitTransform(self):\n",
    "\n",
    "        \"\"\"\n",
    "        split perspective transform images\n",
    "        \"\"\"\n",
    "        #path_merge = \"transform\"\n",
    "        #path_train = \"transform/data/\"\n",
    "        #path_label = \"transform/label/\"\n",
    "        path_merge = \"deform/deform_norm2\"\n",
    "        path_train = \"deform/train/\"\n",
    "        path_label = \"deform/label/\"\n",
    "        train_imgs = glob.glob(path_merge+\"/*.\"+self.img_type)\n",
    "        for imgname in train_imgs:\n",
    "            midname = imgname[imgname.rindex(\"/\")+1:imgname.rindex(\".\"+self.img_type)]\n",
    "            img = cv2.imread(imgname)\n",
    "            img_train = img[:,:,2]#cv2 read image rgb->bgr\n",
    "            img_label = img[:,:,0]\n",
    "            cv2.imwrite(path_train+midname+\".\"+self.img_type,img_train)\n",
    "            cv2.imwrite(path_label+midname+\".\"+self.img_type,img_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class dataProcess(object):\n",
    "\n",
    "    def __init__(self, out_rows, out_cols, data_path = \"../media/combined_37_UDB/14/\", label_path = \"../media/combined_37_UDB/14/\", \n",
    "                 train_dirs = train_dirs, test_dirs = test_dirs, test_path =  \"../media/combined_37_UDB/14/\", npy_path = \"../media/combined_37_UDB/14/\", img_type = \"png\"):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        self.out_rows = out_rows\n",
    "        self.out_cols = out_cols\n",
    "        self.data_path = data_path\n",
    "        self.label_path = label_path\n",
    "        self.img_type = img_type\n",
    "        self.test_path = test_path\n",
    "        self.npy_path = npy_path\n",
    "\n",
    "    def create_train_data(self):\n",
    "        print('-'*30)\n",
    "        print('Creating training images...')\n",
    "        print('-'*30)\n",
    "        imgs = []\n",
    "        for train_dir in train_dirs:\n",
    "            imgs.extend([x for x in glob.glob(\"../media/combined_37_UDB/14/%s\" % train_dir +\"/*.\"+\"png\") if 'mask' not in x])\n",
    "        print(len(imgs))\n",
    "        imgdatas = np.ndarray((len(imgs), 256, 256, 1), dtype=np.uint8)\n",
    "        imglabels = np.ndarray((len(imgs), 256, 256,1), dtype=np.uint8) # buildings\n",
    "        \n",
    "        i = 0\n",
    "        for imgname in imgs:\n",
    "            midname = imgname[imgname.rindex(\"/\")+1:]\n",
    "            img = load_img(imgname,grayscale = True)\n",
    "            try:\n",
    "                label = load_img(imgname.split('\\\\')[0]  + '/' + imgname.split('\\\\')[1].split('.')[0] + '_mask.png',grayscale = True)\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "            img = img_to_array(img)\n",
    "            label = img_to_array(label)\n",
    "            \n",
    "            imgdatas[i] = img\n",
    "            imglabels[i] = label\n",
    "            \n",
    "            i += 1\n",
    "            \n",
    "        print('loading done')\n",
    "        np.save(self.npy_path + '/imgs_train.npy', imgdatas)\n",
    "        np.save(self.npy_path + '/imgs_mask_train.npy', imglabels)\n",
    "        print('Saving to .npy files done.')\n",
    "\n",
    "    def create_test_data(self):\n",
    "        i = 0\n",
    "        print('-'*30)\n",
    "        print('Creating test images...')\n",
    "        print('-'*30)\n",
    "        imgs = []\n",
    "        for test_dir in test_dirs:\n",
    "            imgs.extend([x for x in glob.glob(\"../media/combined_37_UDB/14/%s\" % test_dir +\"/*.\"+\"png\") if 'mask' not in x])\n",
    "        print(len(imgs))\n",
    "        imgdatas = np.ndarray((len(imgs),256,256,1), dtype=np.uint8)\n",
    "        \n",
    "        i = 0\n",
    "        for imgname in imgs:\n",
    "            midname = imgname[imgname.rindex(\"/\")+1:]\n",
    "            img = load_img(imgname,grayscale = True)\n",
    "            img = img_to_array(img)\n",
    "            \n",
    "            imgdatas[i] = img\n",
    "            \n",
    "            i += 1\n",
    "\n",
    "        print('loading done')\n",
    "        np.save(self.npy_path + '/imgs_test.npy', imgdatas)\n",
    "        print('Saving to imgs_test.npy files done.')\n",
    "\n",
    "    def load_train_data(self, tp = 'roads'):\n",
    "        print('-'*30)\n",
    "        print('load train images...')\n",
    "        print('-'*30)\n",
    "        imgs_train = np.load(self.npy_path+\"/imgs_train.npy\")\n",
    "        if tp == 'roads':\n",
    "            imgs_mask_train = np.load(self.npy_path+\"/imgs_mask_train.npy\")\n",
    "        imgs_train = imgs_train.astype('float32')\n",
    "        imgs_mask_train = imgs_mask_train.astype('float32')\n",
    "        imgs_train /= 255\n",
    "        imgs_mask_train /= 255\n",
    "        imgs_mask_train[imgs_mask_train > 0.5] = 1\n",
    "        imgs_mask_train[imgs_mask_train <= 0.5] = 0\n",
    "        return imgs_train,imgs_mask_train\n",
    "\n",
    "    def load_test_data(self):\n",
    "        print('-'*30)\n",
    "        print('load test images...')\n",
    "        print('-'*30)\n",
    "        imgs_test = np.load(self.npy_path+\"/imgs_test.npy\")\n",
    "        imgs_test = imgs_test.astype('float32')\n",
    "        imgs_test /= 255\n",
    "        return imgs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#aug = myAugmentation()\n",
    "#aug.Augmentation()\n",
    "#aug.splitMerge()\n",
    "#aug.splitTransform()\n",
    "mydata = dataProcess(256,256)\n",
    "# mydata.create_train_data()\n",
    "# mydata.create_test_data()\n",
    "#imgs_train,imgs_mask_train = mydata.load_train_data()\n",
    "#print imgs_train.shape,imgs_mask_train.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
